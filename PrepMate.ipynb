{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgGSUTvoY22v"
      },
      "source": [
        "# PrepMate Using RAG and Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjIEndNlaHn8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "G46R_9BTYElj"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain python-dotenv tiktoken langchain-pinecone langchainhub pandas langchain_community pymupdf langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KF0R3yf6Yqa1"
      },
      "outputs": [],
      "source": [
        "# GLOBAL\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "from uuid import uuid4\n",
        "# from tqdm import tqdm\n",
        "from dotenv import load_dotenv\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "\n",
        "# LANGCHAIN\n",
        "import langchain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# VECTOR STORE\n",
        "import pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# AGENTS\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.agents import AgentExecutor, Tool, AgentType\n",
        "from langchain.agents.react.agent import create_react_agent\n",
        "from langchain import hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6rUAQ0iyZD08"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = ' '\n",
        "os.environ['LANGCHAIN_API_KEY'] = ' '\n",
        "os.environ['GOOGLE_API_KEY'] = ' '\n",
        "os.environ['PINECONE_API_KEY'] = ' '\n",
        "os.environ['TAVILY_API_KEY'] = ' '\n",
        "\n",
        "\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "import google.generativeai as genai\n",
        "GOOGLE_API_KEY= os.getenv('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVUz9k4VaKv_"
      },
      "source": [
        "## Loading Documents\n",
        "There are several Document Loaders in the LangChain library depending on the type of file to be used. The most common ones include CSV, HTML, JSON, Markdown, File Directory or Microsoft Office formats.\n",
        "\n",
        "However, there is a more extensive [list](https://python.langchain.com/docs/integrations/document_loaders/google_drive/), where you can load directly from Google Cloud, Notion, Youtube or many other services.\n",
        "\n",
        "We will be using a Pdf file, so we will use the PyMuPdfLoader. Below you can find the code to load the file. As arguments we are using:\n",
        "\n",
        "- **file path**\n",
        "\n",
        "Loading the data in this way will benefit our RAG pipeline. The benefits of metadata are listed further below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-oG7dPiaXTM",
        "outputId": "08c528e8-0632-47cc-edf2-594302c672b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "loader = PyMuPDFLoader(\"./ilets.pdf\") # Load the document\n",
        "data = loader.load()\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V1vhLbrb7NF"
      },
      "source": [
        "## Indexing\n",
        "The **Vector Store Index** is a tool that embeds your documents into vector representations. When you want to search through these embeddings, your query is also converted into a vector embedding. Then, the Vector Store Index performs a mathematical operation to rank all the document embeddings based on how semantically similar they are to your query embedding.\n",
        "\n",
        "The key steps are:\n",
        "- Embedding your documents into vectors\n",
        "- Turning your search query into a vector\n",
        "- Comparing the query vector to all the document vectors\n",
        "- Ranking the document vectors by their similarity to the query vector\n",
        "- Returning the most relevant documents based on this ranking\n",
        "\n",
        "This allows you to search your document collection in a semantic, meaning-based way, rather than just looking for exact keyword matches.\n",
        "\n",
        "To understand the process of vector search, we will analyze the concepts of tokenization, similarity, and embedding, which are implemented by embedding models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4qiUuUUcDYN"
      },
      "source": [
        "According to OpenAI, as a rule of thumb 1 token corresponds to 4 characters of text for common English text. This means that 100 tokens correspond to 75 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMvIEZI0cFMG"
      },
      "source": [
        "## Embeddings\n",
        "Embeddings are a way to represent high-dimensional sparse data like words in a more compact, lower-dimensional form while preserving the meaningful similarities between the original data points.. The key ideas are:\n",
        "\n",
        "- **Capturing Similarities:** Similar items, like synonymous words, will have embedding vectors that are close to each other.\n",
        "\n",
        "- **Spatial Representation:** The embedding vectors are positioned in a multi-dimensional space such that the distance between them (e.g. cosine similarity) reflects how related the original data points are\n",
        "\n",
        "<img width=\"1000\" alt=\"Untitled (1)\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/a7e044ab-2c40-47a2-bb05-e86962790ce0\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDL93YP7cKar"
      },
      "source": [
        "### Cosine Similarity\n",
        "The most common metric used for similarity search is **cosine similarity**. It finds application in scenarios like semantic search and document classification, because it enables the comparison of vector directions, effectively assessing the overall content of documents. By comparing the vector representations of the query and the documents, cosine similarity can identify the most similar and relevant documents to return in the search results.\n",
        "\n",
        "<img width=\"1000\" alt=\"Screenshot 2024-05-02 123447\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/f5356422-29d6-4a4c-8e11-267ad9115b51\">\n",
        "\n",
        "\n",
        "\n",
        "Cosine similarity is a measure of the similarity between two non-zero vectors. It calculates the cosine of the angle between the two vectors, which results in a value between 1 (identical) and -1 (opposite).\n",
        "\n",
        "<img width=\"1000\" alt=\"Screenshot 2024-05-02 122629\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/4215ba02-1fb9-4a72-ad9c-e88740b5a71a\">\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "03yTq4bGcXHa"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(query_emb, document_emb):\n",
        "\n",
        "    # Calculate the dot product of the query and document embeddings\n",
        "    dot_product = np.dot(query_emb, document_emb)\n",
        "\n",
        "    # Calculate the L2 norms (magnitudes) of the query and document embeddings\n",
        "    query_norm = np.linalg.norm(query_emb)\n",
        "    document_norm = np.linalg.norm(document_emb)\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    cosine_sim = dot_product / (query_norm * document_norm)\n",
        "    return cosine_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6MmSFuicRyV"
      },
      "source": [
        "**Simple Example of Cosine Similarity**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHrZmJjxcnVl",
        "outputId": "42062fea-6446-4439-847e-fd5824f05fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Dimensions: 768\n",
            "Document Dimensions: 768\n",
            "Cosine Similarity: 0.6663191415538716\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "question = \"what is ILETS?\"\n",
        "document = \"IELTS stands for the International English Language Testing System – an English Language proficiency test. Globally, there are more than 4 million test takers a year, making IELTS the world’s most popular English language proficiency test for higher education and global migration. IELTS is developed and run by the British Council in partnership with IDP Education and Cambridge Assessment English.\"\n",
        "\n",
        "# Using Google Generative AI EMbeddings Model\n",
        "\n",
        "query_emb = embeddings.embed_query(question)\n",
        "document_emb = embeddings.embed_query(document)\n",
        "cosine_sim = cosine_similarity(query_emb, document_emb)\n",
        "print(f'Query Dimensions: {len(query_emb)}')\n",
        "print(f'Document Dimensions: {len(document_emb)}')\n",
        "print(\"Cosine Similarity:\", cosine_sim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQyrahFc-pw"
      },
      "source": [
        "## Text Splitting\n",
        "\n",
        "Unfortunatelly, LLM models have some limitations when it comes to the point of processing text. One of those is the **context window**. The context window represents the maximum amount of text/tokens that a model can process at one time as an input to generate a response. Therefore we need to split our documents into smaller chunks that can fit into the model's context window. A complete list of OpenAI models can be found [here](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4). It spans from 4'096 tokens for the `gpt-3.5-turbo-instruct` to the `gpt-4-turbo` with 128'000 tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZqLCrQtdBYO"
      },
      "source": [
        "Like the data loaders, LangChain offers several text splitters. In the table below you can see the main splitting methods and when to use which one. The `Adds Metadata` does not mean that it will add (or not) the metadata from the previous loader. For example for HTML has a `HTMLHeaderTextSplitter` and it means it will splits text at the element level and adds metadata for each chunk based on header text.\n",
        "\n",
        "In our case we already have the metadata available and we do not need to add them using and splitter.\n",
        "\n",
        "<img width=\"863\" alt=\"Screenshot 2024-04-30 132645\" src=\"https://github.com/benitomartin/mlops-car-prices/assets/116911431/7b4dcefb-9320-4085-821f-1b21c81f4d28\">\n",
        "\n",
        "\n",
        "**Source:** https://js.langchain.com/v0.1/docs/modules/data_connection/document_transformers/\n",
        "\n",
        "The `RecursiveCharacterTextSplitter` is the recommended tool for splitting general text. It segments the text based on a defined chunk size, using a list of characters as separators.\n",
        "\n",
        "According to LangChain, the default separators include [\"\\n\\n\", \"\\n\", \" \", \"\"]. This means it aims to keep paragraphs together first, followed by sentences and words, as they typically exhibit the strongest semantic connections in text.\n",
        "\n",
        "To leverage this feature, we can utilize the `RecursiveCharacterTextSplitter` along with the tiktoken library to ensure that splits do not exceed the maximum token chunk size allowed by the language model. Each split will be recursively divided if its size exceeds the limit.\n",
        "\n",
        "The final design of our text splitter will be as follows:\n",
        "\n",
        "- Model: `Gemini Pro` with a context window of 16,385 tokens\n",
        "\n",
        "- Chunk Size: number of tokens of one chunk\n",
        "\n",
        "- Chunk Overlap: number of tokens that overlap between two consecutive chunks\n",
        "\n",
        "- Separators: the order of separators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MyQ4Ex4EdNB-"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=20,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-YRJffxdLcg"
      },
      "source": [
        "## Vector Stores\n",
        "A Vector Store is a specialized database that is designed to store and manage high-dimensional vector data. Vector databases store data in the form of vector embedding, which can be retrieved by the LLMs and allow them to understand the context and meaning of the data, allowing better responses.\n",
        "\n",
        "### Indexing\n",
        "Pinecone is a serverless vector store, which shows a very good performance for a fast vector search and retrieval process.\n",
        "\n",
        "The first step to use Pinecone is to create an Index where our embeddings will be stored. There are several parameters to be considered for this:\n",
        "\n",
        "- Index name\n",
        "- Dimension: must be equal to the embedding model dimensions\n",
        "- Metric: must match with the used to tain the embedding model for better results\n",
        "- Serverless specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rIWEwWvldev7"
      },
      "outputs": [],
      "source": [
        "index_name = \"langchain-pinecone-hammad\"\n",
        "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
        "pc = Pinecone(api_key = PINECONE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "fYP87ayueCpN"
      },
      "outputs": [],
      "source": [
        "pc.delete_index(index_name)   # Deletes the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4qFjfcf5dlZA"
      },
      "outputs": [],
      "source": [
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"))\n",
        "\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2buGphINeJkn",
        "outputId": "eabe4a02-5d00-4a20-f457-e8c2888ccdc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtxf7k-qeUA_"
      },
      "source": [
        "### Namespaces\n",
        "Pinecone allows you to split the data into namespaces within an index. This allows to send queries to an specific namespace. You could for example split your data by content, language or any other index suitable for your use case.\n",
        "\n",
        "For this specific example we will first upload 100 records of our data to a namespace and then we will create two splits each with 50 records. In total we will have 3 namspaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FXt8JHYDePwL"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(data)\n",
        "embed = embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "db = PineconeVectorStore.from_documents(documents=splits,\n",
        "                                        embedding=embed,\n",
        "                                        index_name=index_name,\n",
        "                                        namespace=\"main\"\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "WoOaL6Ylekim"
      },
      "outputs": [],
      "source": [
        "vectorstore = PineconeVectorStore(index_name=index_name,\n",
        "                                  namespace=\"main\",\n",
        "                                  embedding=embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FULremwbeoht",
        "outputId": "3ff92a1f-bedf-459d-f8c1-2e7e71d1bf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------Result Nr. 0-------\n",
            "Page Content: fluency. The last one, “Grammatical Range and Accuracy” examines your use of grammatical structures \n",
            "like the correct use of tenses. Using complex sentences, a variety of tenses, and advanced verb forms \n",
            "like passive voice will help you get a higher mark in this section. However, note the word “Accuracy” in \n",
            "the title. It is more important to be correct than to be adventurous in your language.  \n",
            "Like all IELTS scores, writing task 1 is evaluated from 0 to 9. To calculate your score, you should add all\n",
            " \n",
            "-------Result Nr. 1-------\n",
            "Page Content: Task 2 \n",
            " \n",
            "Overview \n",
            "IELTS writing task 2 is the second and most important task of the writing examination. In this task you \n",
            "are presented with a topic and you are asked to write an essay of at least 250 words responding to it. \n",
            "The topic can be an opinion, an argument, or a troublesome situation, and you are expected to respond \n",
            "to it in some way, depending on the question. You might be asked to give your opinion on the topic,\n",
            " \n",
            "-------Result Nr. 2-------\n",
            "Page Content: Task 1 \n",
            "The IELTS writing task 1 is the first task of the writing examination of IELTS. You are asked to write a \n",
            "minimum 150-word essay describing some sort of visual information, which can be one or more line \n",
            "graphs, pie or bar charts, tables, maps, or diagrams that depict a process. The purpose is to demonstrate \n",
            "that you are able to present given data and observe tendencies, comparing percentages or changes and\n",
            " \n",
            "-------Result Nr. 3-------\n",
            "Page Content: look elsewhere for advice.) The book will be divided into two parts, according to the construction of the \n",
            "exam. \n",
            "There are two tasks in the IELTS writing exam. The first is a “report” on a piece of visual data like a chart \n",
            "or a map, and the second is a more conventional essay. You are given one hour to complete both tasks.\n",
            " \n"
          ]
        }
      ],
      "source": [
        "query = \"What is ILETS Writting Task 1\"\n",
        "similarity = vectorstore.similarity_search(query, k=4)\n",
        "\n",
        "for i in range(len(similarity)):\n",
        "  print(f\"-------Result Nr. {i}-------\")\n",
        "  print(f\"Page Content: {similarity[i].page_content}\")\n",
        "  print(f\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrrNVqVEe-0W",
        "outputId": "19c20bc1-a1c9-4564-f987-1b7ce932cf87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'main': {'vector_count': 389}},\n",
              " 'total_vector_count': 389}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zflUx9PHe8W5"
      },
      "source": [
        "# RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Vf7O8x0cfF5Q"
      },
      "outputs": [],
      "source": [
        "embed = embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vectorstore = PineconeVectorStore(index_name=index_name,\n",
        "                                  namespace=\"main\",\n",
        "                                  embedding=embed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWY-iqR6fOH9"
      },
      "source": [
        "### Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9q9slcdfM1l",
        "outputId": "7fc4e1d7-469a-442d-9bc8-8888be1a0cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-8fd70e3349be>:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  conversational_memory = ConversationBufferWindowMemory(memory_key='chat_history',k=5,return_messages=True)\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI  # Import the Google Generative AI model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "# Conversational memory\n",
        "conversational_memory = ConversationBufferWindowMemory(memory_key='chat_history',k=5,return_messages=True)\n",
        "# Retrieval qa chain\n",
        "qa_db = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=vectorstore.as_retriever())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXlZaGKpfWAr"
      },
      "source": [
        "### Augmented\n",
        "We are going to use a slightly modified prompt template. First we download the react template, which is a common template using toools and agents and then we will add the instruction of in which tool to look up first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOFg2LirfhCT"
      },
      "source": [
        "A collection of templates can be found in the [langchain hub](https://smith.langchain.com/hub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z12G_fJCfcKu",
        "outputId": "da2c00c2-b610-41c8-89e5-04f78c462805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ],
      "source": [
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "print(prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sya51pvaf_TD"
      },
      "source": [
        "Now we will replace this line:\n",
        "\n",
        "`Action: the action to take, should be one of [{tool_names}]`\n",
        "\n",
        "By this line:\n",
        "\n",
        "`Action: the action to take, should be one of [{tool_names}]. Always look first in Pinecone Document Store`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3oBpW9jgBaX"
      },
      "outputs": [],
      "source": [
        "template= '''\n",
        "          Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "          {tools}\n",
        "\n",
        "          Use the following format:\n",
        "\n",
        "          Question: the input question you must answer\n",
        "          Thought: you should always think about what to do\n",
        "          Action: the action to take, should be one of [{tool_names}]. Always look first in Pinecone Document Store if not then use the tool\n",
        "          Action Input: the input to the action\n",
        "          Observation: the result of the action\n",
        "          ... (this Thought/Action/Action Input/Observation can repeat 2 times)\n",
        "          Thought: I now know the final answer\n",
        "          Final Answer: the final answer to the original input question\n",
        "\n",
        "          Begin!\n",
        "\n",
        "          Question: {input}\n",
        "          Thought:{agent_scratchpad}\n",
        "          '''\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "196d34lvgHWr"
      },
      "source": [
        "### Generation With Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcNxmgbbgMYS"
      },
      "source": [
        "We are going to set up 2 tools for our agent:\n",
        "\n",
        "- Tavily Search API: Tavily search over several sources like Bing or Google and returns the most relevant content. It offers 1000 API calls per month for free.\n",
        "\n",
        "- Vectorstore: Our vector store will be used to look for the information first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rC5LFdo9gFEP"
      },
      "outputs": [],
      "source": [
        "# Set up tools and agent\n",
        "import os\n",
        "\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "\n",
        "tavily = TavilySearchResults(max_results=10, tavily_api_key=TAVILY_API_KEY)\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Pinecone Document Store\",\n",
        "        func = qa_db.run,\n",
        "        description = \"This agent looks up information from the Pinecone Document Store\"\n",
        "    ),\n",
        "\n",
        "    Tool(\n",
        "        name=\"Tavily\",\n",
        "        func=tavily.run,\n",
        "        description=\"If the information is not found by Pinecone Agent, this lookup information from Tavily\",\n",
        "    )\n",
        "\n",
        "     # email sender tool\n",
        "\n",
        "]\n",
        "agent = create_react_agent(llm,tools,prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "                        tools=tools,\n",
        "                        agent=agent,\n",
        "                        handle_parsing_errors=True,\n",
        "                        verbose=True,\n",
        "                        memory=conversational_memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bEmC8tNgRGq"
      },
      "source": [
        "Now that every thing is set up, let's run the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn5pOf7dgUOV",
        "outputId": "eeaf4f00-ae16-477d-c1da-ce0e50507356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query about the document: Who is David S. Wills\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should first try to find information about David S. Wills using the Pinecone Document Store.  If that fails, I'll use Tavily.\n",
            "\n",
            "Action: Pinecone Document Store\n",
            "Action Input: \"David S. Wills\"\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mDavid S. Wills is an IELTS tutor from Scotland who has been teaching IELTS since 2010, specializing in writing skills.  He has helped hundreds of students improve their IELTS scores for immigration purposes. He also runs the website www.ted-ielts.com and is the author of \"A Complete Guide to IELTS Writing\".\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I found the information in Pinecone, so I don't need to use Tavily.\n",
            "\n",
            "Thought: I now know the final answer.\n",
            "Final Answer: David S. Wills is an IELTS tutor from Scotland who has been teaching IELTS since 2010, specializing in writing skills. He has helped hundreds of students improve their IELTS scores for immigration purposes. He also runs the website www.ted-ielts.com and is the author of \"A Complete Guide to IELTS Writing\".\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "ques = input('Enter your query about the document: ')\n",
        "response = agent_executor.invoke({\"input\": f\"{ques}\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXyQNtqsgrrS"
      },
      "source": [
        "Let's try a query that doesn't have the answer in the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD0bW1lpgyj-",
        "outputId": "c8fea947-0309-497b-b011-4fc47102dd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query about the document: What is ilets reading \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find information about ilets reading.  I'll first try Pinecone to see if it has any relevant documents.\n",
            "\n",
            "Action: Pinecone Document Store\n",
            "Action Input: \"ilets reading\"\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mI'm sorry, but I don't have enough information to answer your question about IELTS reading.  The provided text focuses on the writing section of the IELTS exam.\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mThought: Pinecone didn't find anything. I'll try Tavily.\n",
            "\n",
            "Action: Tavily\n",
            "Action Input: \"What is the IELTS reading test like?\"\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.ieltslounge.com/how-is-the-reading-test-in-ielts/', 'content': \"The IELTS Reading Test is a crucial part of the IELTS exam, whether you're taking the Academic or General format. It assesses your reading skills through various tasks, helping you demonstrate your ability to understand and interpret text. ... Familiarize yourself with other types like Matching Headings and Sentence Completion. Knowing what\"}, {'url': 'https://englishproficiency.com/ielts/reading/', 'content': 'The IELTS Academic Reading Test is intended for those who aspire to pursue higher studies and professional registration. Like the IELTS General Training Reading Test, it also takes minutes and has 40 questions to answer. There are three long texts that are excerpts from books, journals, magazines, and newspapers.'}, {'url': 'https://ielts.idp.com/vietnam/prepare/article-manage-time-in-ielts-reading/en-gb', 'content': 'IELTS UKVI. If you would like to study at undergraduate or postgraduate level in the UK, you can take IELTS UKVI. Book now Explore test. ... The IELTS Reading test consists of 40 questions, designed to test a wide range of reading skills. These include reading for gist, reading for main ideas, reading for detail, skimming, understanding logical'}, {'url': 'https://takeielts.britishcouncil.org/take-ielts/test-format', 'content': 'Book an IELTS test Information about the IELTS test The IELTS Reading test takes approximately 60 minutes, including the time it takes to transfer your answers from your question booklet to your answer sheet. The IELTS Reading test takes approximately 60 minutes, including the time it takes to transfer your answers from your question booklet to your answer sheet. The IELTS Writing test takes 60 minutes. Your Writing test will be marked by a certificated IELTS examiner. The topics used in the IELTS General Training Writing test are of general interest. The IELTS Writing test takes 60 minutes. Your Writing test will be marked by a certificated IELTS examiner. You will talk to a certified examiner in the IELTS Speaking test. Book an IELTS test'}, {'url': 'https://www.ielts.ca/take-ielts/ielts-test-format/', 'content': 'The IELTS test format is exactly the same on the computer as it is in a traditional paper exam. Both tests include the same content and are still completed with a test centre, but the Reading, Writing and Listening sections are just filled out differently. The Speaking section of the test will still be carried out face to face with an examiner.'}, {'url': 'https://ielts.idp.com/uae/prepare/article-ielts-reading-test', 'content': 'There are three sections to the Reading test, and you will have about 60 minutes to respond to 40 questions. Test format. The 40 questions on the IELTS Reading test evaluate a variety of reading skills. These include: Skimming - reading for gist and to understand the main idea . Scanning - reading quickly to locate a specific piece of information'}, {'url': 'https://ielts-up.com/reading/ielts-reading-practice.html', 'content': 'IELTS Reading Practice Tests - IELTS-up * Listening* Reading* Writing* Speaking Here you can find full IELTS Reading Test Samples (both General and Academic) for IELTS reading practice. IELTS Academic Reading test 1 (40 questions) IELTS Academic Reading test 2 (40 questions) IELTS Academic Reading test 3 (40 questions) IELTS Academic Reading test 4 (40 questions) IELTS Academic Reading test 5 (40 questions) IELTS Academic Reading test 6 (40 questions) IELTS Academic Reading test 7 (40 questions) IELTS Academic Reading test 8 (40 questions) IELTS Academic Reading test 9 (40 questions) IELTS Academic Reading test 10 (40 questions) IELTS Academic Reading test 11 (40 questions) IELTS General Reading test 1 (40 questions) IELTS General Reading test 2 (40 questions)'}, {'url': 'https://ieltsprogress.com/what-is-it-like-to-run-a-large-supermarket-answers/', 'content': 'IELTS General Test - Passage 10: What is it like to run a large supermarket? reading with answers explanation, location and pdf summary. This reading paragraph has been taken from our huge collection of Academic & General Training (GT) Reading practice test PDFs.'}, {'url': 'https://ielts-up.com/reading/ielts-reading-test.html', 'content': \"IELTS Reading. On this page you will find all the information you need to know about IELTS Reading test.You will also see IELTS Reading marking scheme and learn different ways how to succeed in IELTS Reading. We'll describe types of questions you may face on the Reading test and give you preparation resources: free IELTS Reading test samples to practise reading, useful IELTS Reading tips and\"}, {'url': 'https://www.ielts.ca/blogs/everything-about-the-ielts-exam/', 'content': 'About the IELTS test format. There are four components to the IELTS test: Listening, Reading, Writing and Speaking. Listening. The Listening test takes approximately 30 minutes and includes 40 questions. There are four sections: Section 1: A conversation between two people, set in an everyday social context.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: Tavily provided several links with information about the IELTS reading test.  I can synthesize this information to answer the question.\n",
            "\n",
            "Thought: I now know the final answer.\n",
            "\n",
            "Final Answer: The IELTS Reading test is a 60-minute section with 40 questions based on three long texts.  The texts are excerpts from books, journals, magazines, and newspapers (for the Academic version) and assess a range of reading skills, including skimming, scanning, understanding main ideas, and reading for detail.  The test format is the same for both computer-based and paper-based tests.  There are various question types, such as matching headings and sentence completion.  Many practice tests are available online.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "ques = input('Enter your query about the document: ')\n",
        "response = agent_executor.invoke({\"input\": f\"{ques}\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojzWJcLtg9F4"
      },
      "source": [
        "Let's check the chat context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "489GvlQeg_PI",
        "outputId": "45d721da-96e3-4997-e9b9-b090ca675c49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content='Who is David S. Wills', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='David S. Wills is an IELTS tutor from Scotland who has been teaching IELTS since 2010, specializing in writing skills. He has helped hundreds of students improve their IELTS scores for immigration purposes. He also runs the website www.ted-ielts.com and is the author of \"A Complete Guide to IELTS Writing\".', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is ilets reading ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The IELTS Reading test is a 60-minute section with 40 questions based on three long texts.  The texts are excerpts from books, journals, magazines, and newspapers (for the Academic version) and assess a range of reading skills, including skimming, scanning, understanding main ideas, and reading for detail.  The test format is the same for both computer-based and paper-based tests.  There are various question types, such as matching headings and sentence completion.  Many practice tests are available online.', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "conversational_memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dktkYu_zhBDz"
      },
      "source": [
        "Now that we are done, let's clear the memory!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcfh5OYrhDkF"
      },
      "outputs": [],
      "source": [
        "agent_executor.memory.clear()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
